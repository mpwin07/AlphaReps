import pandas as pd
import numpy as np
import cv2
import mediapipe as mp
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
import pickle
import os
from typing import List, Tuple, Optional
import asyncio

class VideoExerciseClassifier:
    def __init__(self, auto_load_model=True):
        # Initialize three models for ensemble
        # Model 1: Random Forest
        self.rf_model = RandomForestClassifier(
            n_estimators=300,
            max_depth=30,
            min_samples_split=2,
            min_samples_leaf=1,
            max_features='sqrt',
            random_state=42,
            class_weight='balanced',
            n_jobs=-1
        )
        
        # Model 2: Gradient Boosting
        self.gb_model = GradientBoostingClassifier(
            n_estimators=200,
            max_depth=10,
            learning_rate=0.1,
            subsample=0.8,
            random_state=42
        )
        
        # Model 3: Support Vector Machine
        self.svm_model = SVC(
            kernel='rbf',
            C=10.0,
            gamma='scale',
            probability=True,
            random_state=42,
            class_weight='balanced'
        )
        
        # Create ensemble voting classifier with all three models
        self.model = VotingClassifier(
            estimators=[
                ('rf', self.rf_model),
                ('gb', self.gb_model),
                ('svm', self.svm_model)
            ],
            voting='soft',  # Use probability-based voting
            n_jobs=-1
        )
        self.label_encoder = LabelEncoder()
        self.scaler = StandardScaler()
        self.feature_selector = None
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(
            static_image_mode=False,
            model_complexity=1,
            enable_segmentation=False,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        self.exercise_classes = [
            'barbell_biceps_curl',
            'hammer_curl', 
            'push_up',
            'shoulder_press',
            'squat'
        ]
        
        # Auto-load trained model if available
        self.model_loaded = False
        if auto_load_model:
            self._try_load_trained_model()
    
    def _try_load_trained_model(self):
        """Try to load a trained model from common locations"""
        model_paths = [
            "models/video_exercise_model.pkl",          # Primary location
            os.path.join(os.path.dirname(__file__), "video_exercise_model.pkl"),  # Same directory
            "backend/models/video_exercise_model.pkl",  # Full backend path
            "scripts/models/video_exercise_model.pkl",  # Legacy training script location
            "../scripts/models/video_exercise_model.pkl" # Legacy relative path
        ]
        
        for model_path in model_paths:
            if os.path.exists(model_path):
                print(f"Found trained model at: {model_path}")
                if self.load_model(model_path):
                    self.model_loaded = True
                    print("Trained model loaded successfully!")
                    return True
                    
        print("No trained model found. Use train_model() to train a new model.")
        return False
        
    def extract_landmarks_from_frame(self, frame: np.ndarray) -> Optional[np.ndarray]:
        """Extract pose landmarks from a single frame with enhanced curl detection"""
        try:
            # Convert BGR to RGB
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # Process the frame
            results = self.pose.process(rgb_frame)
            
            return self.extract_landmarks_from_results(results)
                
        except Exception as e:
            print(f"Error extracting landmarks: {e}")
            return None
    
    def extract_landmarks_from_results(self, results) -> Optional[np.ndarray]:
        """Extract landmarks from existing MediaPipe results (optimized for reuse)"""
        try:
            if results.pose_landmarks:
                # Extract basic landmark coordinates
                landmarks = []
                for landmark in results.pose_landmarks.landmark:
                    landmarks.extend([
                        landmark.x,
                        landmark.y,
                        landmark.z,
                        landmark.visibility
                    ])
                
                # Add enhanced features for curl differentiation (simplified for speed)
                enhanced_features = self.extract_curl_specific_features_fast(results.pose_landmarks)
                landmarks.extend(enhanced_features)
                
                # Ensure exactly 146 features (132 basic + 14 enhanced)
                final_landmarks = landmarks[:146]  # Truncate if too long
                while len(final_landmarks) < 146:  # Pad if too short
                    final_landmarks.append(0.0)
                
                return np.array(final_landmarks)
            else:
                return None
                
        except Exception as e:
            print(f"Error extracting landmarks from results: {e}")
            return None
    
    def extract_curl_specific_features(self, pose_landmarks) -> List[float]:
        """Extract additional features to distinguish between curl types - more robust version"""
        try:
            landmarks = pose_landmarks.landmark
            
            # Get key landmarks for curl analysis with fallback values
            def get_landmark_safe(idx, default_x=0.5, default_y=0.5, default_z=0.0):
                if idx < len(landmarks):
                    lm = landmarks[idx]
                    # Check if landmark is visible enough
                    if lm.visibility > 0.3:
                        return lm
                # Return a default landmark-like object
                class DefaultLandmark:
                    def __init__(self, x, y, z, v):
                        self.x, self.y, self.z, self.visibility = x, y, z, v
                return DefaultLandmark(default_x, default_y, default_z, 0.5)
            
            # Get landmarks with safe fallbacks
            left_shoulder = get_landmark_safe(11)
            right_shoulder = get_landmark_safe(12)
            left_elbow = get_landmark_safe(13)
            right_elbow = get_landmark_safe(14)
            left_wrist = get_landmark_safe(15)
            right_wrist = get_landmark_safe(16)
            left_pinky = get_landmark_safe(17, left_wrist.x - 0.05, left_wrist.y)
            right_pinky = get_landmark_safe(18, right_wrist.x + 0.05, right_wrist.y)
            left_index = get_landmark_safe(19, left_wrist.x - 0.03, left_wrist.y)
            right_index = get_landmark_safe(20, right_wrist.x + 0.03, right_wrist.y)
            left_thumb = get_landmark_safe(21, left_wrist.x - 0.02, left_wrist.y - 0.02)
            right_thumb = get_landmark_safe(22, right_wrist.x + 0.02, right_wrist.y - 0.02)
            
            features = []
            
            # 1. Basic arm geometry (always available)
            # Elbow angles
            left_elbow_angle = self.calculate_angle_3d(
                (left_shoulder.x, left_shoulder.y, left_shoulder.z),
                (left_elbow.x, left_elbow.y, left_elbow.z),
                (left_wrist.x, left_wrist.y, left_wrist.z)
            )
            right_elbow_angle = self.calculate_angle_3d(
                (right_shoulder.x, right_shoulder.y, right_shoulder.z),
                (right_elbow.x, right_elbow.y, right_elbow.z),
                (right_wrist.x, right_wrist.y, right_wrist.z)
            )
            features.extend([left_elbow_angle, right_elbow_angle])
            
            # 2. Wrist-elbow distances (indicates arm extension)
            left_wrist_elbow_dist = abs(left_wrist.x - left_elbow.x) + abs(left_wrist.y - left_elbow.y)
            right_wrist_elbow_dist = abs(right_wrist.x - right_elbow.x) + abs(right_wrist.y - right_elbow.y)
            features.extend([left_wrist_elbow_dist, right_wrist_elbow_dist])
            
            # 3. Hand orientation features (if hand landmarks are visible)
            left_thumb_pinky_dist = abs(left_thumb.x - left_pinky.x) + abs(left_thumb.y - left_pinky.y)
            right_thumb_pinky_dist = abs(right_thumb.x - right_pinky.x) + abs(right_thumb.y - right_pinky.y)
            features.extend([left_thumb_pinky_dist, right_thumb_pinky_dist])
            
            # 4. Thumb-wrist positioning
            left_thumb_wrist_x_diff = left_thumb.x - left_wrist.x
            right_thumb_wrist_x_diff = right_thumb.x - right_wrist.x
            features.extend([left_thumb_wrist_x_diff, right_thumb_wrist_x_diff])
            
            # 5. Index finger positioning
            left_index_wrist_dist = abs(left_index.x - left_wrist.x) + abs(left_index.y - left_wrist.y)
            right_index_wrist_dist = abs(right_index.x - right_wrist.x) + abs(right_index.y - right_wrist.y)
            features.extend([left_index_wrist_dist, right_index_wrist_dist])
            
            # 6. Simplified hand spread
            left_pinky_index_dist = abs(left_pinky.x - left_index.x) + abs(left_pinky.y - left_index.y)
            right_pinky_index_dist = abs(right_pinky.x - right_index.x) + abs(right_pinky.y - right_index.y)
            features.extend([left_pinky_index_dist, right_pinky_index_dist])
            
            # 7. Wrist depth variation (simplified)
            left_wrist_depth = left_wrist.z
            right_wrist_depth = right_wrist.z
            features.extend([left_wrist_depth, right_wrist_depth])
            
            # Ensure we always return exactly 14 features
            while len(features) < 14:
                features.append(0.0)
            
            return features[:14]  # Ensure exactly 14 features
            
        except Exception as e:
            print(f"Warning: Using default curl features due to error: {e}")
            # Return reasonable default values instead of zeros
            return [90.0, 90.0, 0.2, 0.2, 0.05, 0.05, 0.0, 0.0, 0.03, 0.03, 0.04, 0.04, 0.0, 0.0]
    
    def extract_curl_specific_features_fast(self, pose_landmarks) -> List[float]:
        """Fast version of curl feature extraction with minimal computation"""
        try:
            landmarks = pose_landmarks.landmark
            
            # Only extract essential features for speed
            features = []
            
            # Basic elbow angles (most important for curl detection)
            if len(landmarks) > 16:
                left_shoulder = landmarks[11]
                left_elbow = landmarks[13]
                left_wrist = landmarks[15]
                right_shoulder = landmarks[12]
                right_elbow = landmarks[14]
                right_wrist = landmarks[16]
                
                # Simple 2D angle calculation (faster than 3D)
                left_angle = self.calculate_angle_2d_fast(
                    (left_shoulder.x, left_shoulder.y),
                    (left_elbow.x, left_elbow.y),
                    (left_wrist.x, left_wrist.y)
                )
                right_angle = self.calculate_angle_2d_fast(
                    (right_shoulder.x, right_shoulder.y),
                    (right_elbow.x, right_elbow.y),
                    (right_wrist.x, right_wrist.y)
                )
                features.extend([left_angle, right_angle])
                
                # Basic wrist positions (simplified)
                features.extend([
                    left_wrist.x - left_elbow.x,
                    right_wrist.x - right_elbow.x,
                    left_wrist.y - left_elbow.y,
                    right_wrist.y - right_elbow.y
                ])
                
                # Fill remaining with simple defaults
                features.extend([0.0] * 8)
            else:
                # Fallback if not enough landmarks
                features = [90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
            
            return features[:14]
            
        except Exception as e:
            # Fast fallback
            return [90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
    
    def calculate_angle_2d_fast(self, point1, point2, point3):
        """Fast 2D angle calculation"""
        try:
            import math
            a = np.array(point1)
            b = np.array(point2)
            c = np.array(point3)
            
            ba = a - b
            bc = c - b
            
            cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))
            cosine_angle = np.clip(cosine_angle, -1.0, 1.0)
            angle = np.arccos(cosine_angle)
            
            return np.degrees(angle)
        except:
            return 90.0
    
    def calculate_angle_3d(self, point1, point2, point3):
        """Calculate angle between three 3D points with NaN protection"""
        try:
            a = np.array(point1)
            b = np.array(point2)  # vertex
            c = np.array(point3)
            
            # Check for NaN or invalid values
            if np.any(np.isnan([a, b, c])) or np.any(np.isinf([a, b, c])):
                return 90.0
            
            ba = a - b
            bc = c - b
            
            # Check for zero vectors (would cause division by zero)
            norm_ba = np.linalg.norm(ba)
            norm_bc = np.linalg.norm(bc)
            
            if norm_ba == 0 or norm_bc == 0:
                return 90.0
            
            cosine_angle = np.dot(ba, bc) / (norm_ba * norm_bc)
            
            # Ensure cosine is in valid range
            cosine_angle = np.clip(cosine_angle, -1.0, 1.0)
            
            # Check if cosine is NaN
            if np.isnan(cosine_angle):
                return 90.0
            
            angle = np.arccos(cosine_angle)
            angle_degrees = np.degrees(angle)
            
            # Final NaN check
            if np.isnan(angle_degrees) or np.isinf(angle_degrees):
                return 90.0
                
            return float(angle_degrees)
        except Exception as e:
            print(f"Angle calculation error: {e}")
            return 90.0  # Default angle
    
    def process_video_file(self, video_path: str, max_frames: int = 30) -> List[np.ndarray]:
        """
        Process a video file and extract pose landmarks from multiple frames
        
        Args:
            video_path: Path to the video file
            max_frames: Maximum number of frames to process per video
            
        Returns:
            List of landmark arrays
        """
        landmarks_list = []
        
        try:
            cap = cv2.VideoCapture(video_path)
            
            if not cap.isOpened():
                print(f"Error opening video: {video_path}")
                return landmarks_list
            
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            # Calculate frame step to get evenly distributed frames
            if total_frames > max_frames:
                frame_step = total_frames // max_frames
            else:
                frame_step = 1
            
            frame_count = 0
            processed_frames = 0
            
            while cap.isOpened() and processed_frames < max_frames:
                ret, frame = cap.read()
                
                if not ret:
                    break
                
                # Process every nth frame
                if frame_count % frame_step == 0:
                    landmarks = self.extract_landmarks_from_frame(frame)
                    if landmarks is not None:
                        landmarks_list.append(landmarks)
                        processed_frames += 1
                
                frame_count += 1
            
            cap.release()
            
        except Exception as e:
            print(f"Error processing video {video_path}: {e}")
        
        return landmarks_list
    
    def prepare_dataset_from_videos(self, data_dir: str = "dataset") -> Tuple[np.ndarray, np.ndarray]:
        """
        Prepare dataset from video files in organized folders
        
        Args:
            data_dir: Directory containing exercise folders with videos
            
        Returns:
            Tuple of (features, labels)
        """
        print("üìä Loading and preparing dataset from videos...")
        
        features = []
        labels = []
        total_videos = 0
        processed_videos = 0
        total_frames = 0
        
        for exercise_name in os.listdir(data_dir):
            exercise_path = os.path.join(data_dir, exercise_name)
            
            if not os.path.isdir(exercise_path):
                continue
            
            print(f"\nüé¨ Processing {exercise_name}...")
            
            video_files = [f for f in os.listdir(exercise_path) if f.endswith('.mp4')]
            total_videos += len(video_files)
            
            exercise_frames = 0
            for i, video_file in enumerate(video_files):
                video_path = os.path.join(exercise_path, video_file)
                
                print(f"  üìπ Video {i+1}/{len(video_files)}: {video_file}")
                
                # Extract landmarks from video
                landmarks_list = self.process_video_file(video_path, max_frames=30)
                
                if landmarks_list:
                    processed_videos += 1
                    # Add each frame's landmarks as a separate sample
                    for landmarks in landmarks_list:
                        features.append(landmarks)
                        labels.append(exercise_name)
                        exercise_frames += 1
                        total_frames += 1
                    print(f"    ‚úÖ Extracted {len(landmarks_list)} frames")
                else:
                    print(f"    ‚ùå No landmarks extracted")
            
            print(f"  üìä {exercise_name}: {exercise_frames} frames from {len(video_files)} videos")
        
        print(f"\nüìà Dataset Summary:")
        print(f"  ‚Ä¢ Total videos: {total_videos}")
        print(f"  ‚Ä¢ Successfully processed: {processed_videos}")
        print(f"  ‚Ä¢ Total frames extracted: {total_frames}")
        print(f"  ‚Ä¢ Success rate: {processed_videos/total_videos*100:.1f}%")
        
        print(f"‚úÖ Dataset prepared: {len(features)} valid samples from {len(set(labels))} exercise types")
        
        # Convert to numpy arrays
        features_array = np.array(features)
        labels_array = np.array(labels)
        
        # Clean NaN values
        print("üßπ Cleaning data...")
        
        # Find rows with NaN values
        nan_mask = np.isnan(features_array).any(axis=1)
        inf_mask = np.isinf(features_array).any(axis=1)
        invalid_mask = nan_mask | inf_mask
        
        if np.any(invalid_mask):
            print(f"‚ö†Ô∏è  Removing {np.sum(invalid_mask)} samples with NaN/Inf values")
            features_array = features_array[~invalid_mask]
            labels_array = labels_array[~invalid_mask]
        
        # Replace any remaining NaN with median values
        from sklearn.impute import SimpleImputer
        imputer = SimpleImputer(strategy='median')
        features_array = imputer.fit_transform(features_array)
        
        print(f"‚úÖ Final dataset: {len(features_array)} clean samples")
        
        return features_array, labels_array
    async def train_model(self, data_dir: str = "dataset"):
        """Train the exercise classification model"""
        print("üèãÔ∏è Training Video Exercise Classification Model...")
        
        # Prepare dataset
        X, y = self.prepare_dataset_from_videos(data_dir)
        
        if len(X) == 0:
            raise ValueError("No valid samples found in dataset")
        
        # Encode labels
        y_encoded = self.label_encoder.fit_transform(y)
        
        # Split dataset
        X_train, X_test, y_train, y_test = train_test_split(
            X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
        )
        
        print(f"Training set: {len(X_train)} samples")
        print(f"Test set: {len(X_test)} samples")
        
        # Data preprocessing
        print("üîß Preprocessing data...")
        
        # Scale features only
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        print(f"üìä Using all {X_train_scaled.shape[1]} features (no feature selection)")
        
        # Train Ensemble Model (RF + GB + SVM)
        print("üéØ Training Ensemble Model (Random Forest + Gradient Boosting + SVM)...")
        print("   ‚Ä¢ Training Random Forest (300 estimators)...")
        print("   ‚Ä¢ Training Gradient Boosting (200 estimators)...")
        print("   ‚Ä¢ Training SVM (RBF kernel)...")
        self.model.fit(X_train_scaled, y_train)
        print("‚úÖ All three models trained successfully!")
        
        # Evaluate model
        y_pred = self.model.predict(X_test_scaled)
        accuracy = accuracy_score(y_test, y_pred)
        
        print(f"‚úÖ Model trained successfully!")
        print(f"üéØ Accuracy: {accuracy:.4f}")
        
        # Print detailed classification report
        target_names = self.label_encoder.classes_
        print("\nüìä Classification Report:")
        print(classification_report(y_test, y_pred, target_names=target_names))
        
        # Save model
        await self.save_model()
        
        return accuracy
    
    async def save_model(self, model_path: str = "models/video_exercise_model.pkl"):
        """Save the trained model and label encoder"""
        os.makedirs(os.path.dirname(model_path), exist_ok=True)
        # Save ensemble model with all preprocessing components
        model_data = {
            'model': self.model,  # VotingClassifier with 3 models
            'rf_model': self.rf_model,
            'gb_model': self.gb_model,
            'svm_model': self.svm_model,
            'label_encoder': self.label_encoder,
            'scaler': self.scaler,
            'feature_selector': self.feature_selector,
            'variance_selector': self.variance_selector if hasattr(self, 'variance_selector') else None,
            'exercise_classes': self.exercise_classes
        }
        
        with open(model_path, 'wb') as f:
            pickle.dump(model_data, f)
        
        print(f" Model saved to {model_path}")
    
    def load_model(self, model_path: str = "models/video_exercise_model.pkl"):
        """Load a pre-trained model"""
        try:
            with open(model_path, 'rb') as f:
                model_data = pickle.load(f)
            
            self.model = model_data['model']
            # Load individual models if available (for ensemble)
            self.rf_model = model_data.get('rf_model', None)
            self.gb_model = model_data.get('gb_model', None)
            self.svm_model = model_data.get('svm_model', None)
            self.label_encoder = model_data['label_encoder']
            self.scaler = model_data.get('scaler', StandardScaler())
            self.feature_selector = model_data.get('feature_selector', None)
            self.variance_selector = model_data.get('variance_selector', None)
            self.exercise_classes = model_data['exercise_classes']
            
            # Set model loaded flag
            self.model_loaded = True
            
            print(f"Model loaded from {model_path}")
            return True
        except Exception as e:
            print(f"Error loading model: {e}")
            self.model_loaded = False
            return False
    
    def predict(self, landmarks: np.ndarray) -> str:
        """
        Predict exercise type from pose landmarks with enhanced preprocessing
        
        Args:
            landmarks: Pose landmarks array (146 features: 132 basic + 14 enhanced)
            
        Returns:
            Predicted exercise name
        """
        try:
            # Check if model is loaded
            if not self.model_loaded:
                print("Model not loaded. Cannot make predictions.")
                return "unknown"
            
            # Reshape if needed
            if landmarks.ndim == 1:
                landmarks = landmarks.reshape(1, -1)
            
            # Apply preprocessing pipeline
            landmarks_processed = self._preprocess_features(landmarks)
            
            # Predict
            prediction = self.model.predict(landmarks_processed)[0]
            exercise_name = self.label_encoder.inverse_transform([prediction])[0]
            
            # Apply curl-specific post-processing
            if exercise_name in ['barbell_biceps_curl', 'hammer_curl']:
                exercise_name = self.refine_curl_prediction(landmarks_processed, exercise_name)
            
            return exercise_name
        except Exception as e:
            print(f"Error in prediction: {e}")
            return "unknown"
    
    def _preprocess_features(self, landmarks: np.ndarray) -> np.ndarray:
        """Apply the same preprocessing pipeline used during training"""
        try:
            # Check if preprocessing components are available
            if not hasattr(self, 'scaler') or self.scaler is None:
                print("Warning: Scaler not available, using raw features")
                return landmarks
            
            # Scale features only (no feature selection)
            landmarks_scaled = self.scaler.transform(landmarks)
            
            return landmarks_scaled
        except Exception as e:
            print(f"Error in preprocessing: {e}")
            print("Falling back to raw features")
            return landmarks
    
    def refine_curl_prediction(self, landmarks: np.ndarray, initial_prediction: str) -> str:
        """
        Refine curl prediction using hand orientation analysis
        
        Args:
            landmarks: Full landmark array
            initial_prediction: Initial model prediction
            
        Returns:
            Refined prediction
        """
        try:
            # Get probabilities for both curl types
            probabilities = self.model.predict_proba(landmarks)[0]
            class_names = self.label_encoder.classes_
            
            # Find indices for curl exercises
            bicep_idx = np.where(class_names == 'barbell_biceps_curl')[0]
            hammer_idx = np.where(class_names == 'hammer_curl')[0]
            
            if len(bicep_idx) == 0 or len(hammer_idx) == 0:
                return initial_prediction
            
            bicep_prob = probabilities[bicep_idx[0]]
            hammer_prob = probabilities[hammer_idx[0]]
            
            # If probabilities are close, use hand orientation features to decide
            if abs(bicep_prob - hammer_prob) < 0.2:  # Close predictions
                # Extract enhanced features (last 14 elements)
                if len(landmarks[0]) >= 146:
                    enhanced_features = landmarks[0][-14:]
                    
                    # Analyze hand orientation indicators
                    thumb_pinky_dists = enhanced_features[0:2]  # Thumb-pinky distances
                    thumb_wrist_diffs = enhanced_features[2:4]  # Thumb-wrist x differences
                    
                    # Hammer curls typically have:
                    # - Smaller thumb-pinky distance (neutral grip)
                    # - Different thumb-wrist positioning
                    avg_thumb_pinky_dist = np.mean(thumb_pinky_dists)
                    avg_thumb_wrist_diff = np.mean(np.abs(thumb_wrist_diffs))
                    
                    # Decision thresholds (may need tuning)
                    if avg_thumb_pinky_dist < 0.05 and avg_thumb_wrist_diff < 0.03:
                        return 'hammer_curl'
                    elif avg_thumb_pinky_dist > 0.08:
                        return 'barbell_biceps_curl'
            
            # Return prediction with higher probability
            return 'barbell_biceps_curl' if bicep_prob > hammer_prob else 'hammer_curl'
            
        except Exception as e:
            print(f"Error in curl refinement: {e}")
            return initial_prediction
    
    def predict_proba(self, landmarks: np.ndarray) -> dict:
        """
        Get prediction probabilities for all exercise classes
        
        Args:
            landmarks: Pose landmarks array
            
        Returns:
            Dictionary with exercise names and their probabilities
        """
        try:
            if landmarks.ndim == 1:
                landmarks = landmarks.reshape(1, -1)
            
            probabilities = self.model.predict_proba(landmarks)[0]
            class_names = self.label_encoder.classes_
            
            return dict(zip(class_names, probabilities))
        except Exception as e:
            print(f"Error in probability prediction: {e}")
            return {}
    
    def get_individual_predictions(self, landmarks: np.ndarray) -> dict:
        """
        Get predictions from each individual model in the ensemble
        
        Args:
            landmarks: Pose landmarks array
            
        Returns:
            Dictionary with predictions from each model
        """
        try:
            if landmarks.ndim == 1:
                landmarks = landmarks.reshape(1, -1)
            
            # Preprocess features
            landmarks_processed = self._preprocess_features(landmarks)
            
            # Get predictions from each model
            predictions = {}
            
            if self.rf_model:
                rf_pred = self.rf_model.predict(landmarks_processed)[0]
                rf_proba = self.rf_model.predict_proba(landmarks_processed)[0]
                predictions['random_forest'] = {
                    'prediction': self.label_encoder.inverse_transform([rf_pred])[0],
                    'confidence': float(max(rf_proba))
                }
            
            if self.gb_model:
                gb_pred = self.gb_model.predict(landmarks_processed)[0]
                gb_proba = self.gb_model.predict_proba(landmarks_processed)[0]
                predictions['gradient_boosting'] = {
                    'prediction': self.label_encoder.inverse_transform([gb_pred])[0],
                    'confidence': float(max(gb_proba))
                }
            
            if self.svm_model:
                svm_pred = self.svm_model.predict(landmarks_processed)[0]
                svm_proba = self.svm_model.predict_proba(landmarks_processed)[0]
                predictions['svm'] = {
                    'prediction': self.label_encoder.inverse_transform([svm_pred])[0],
                    'confidence': float(max(svm_proba))
                }
            
            # Get ensemble prediction
            ensemble_pred = self.model.predict(landmarks_processed)[0]
            ensemble_proba = self.model.predict_proba(landmarks_processed)[0]
            predictions['ensemble'] = {
                'prediction': self.label_encoder.inverse_transform([ensemble_pred])[0],
                'confidence': float(max(ensemble_proba))
            }
            
            return predictions
        except Exception as e:
            print(f"Error getting individual predictions: {e}")
            return {}
    
    def get_feature_importance(self) -> dict:
        """Get feature importance from the Random Forest model in the ensemble"""
        if self.rf_model and hasattr(self.rf_model, 'feature_importances_'):
            # Create feature names (33 landmarks √ó 4 coordinates each)
            feature_names = []
            landmark_names = [
                'nose', 'left_eye_inner', 'left_eye', 'left_eye_outer',
                'right_eye_inner', 'right_eye', 'right_eye_outer',
                'left_ear', 'right_ear', 'mouth_left', 'mouth_right',
                'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',
                'left_wrist', 'right_wrist', 'left_pinky', 'right_pinky',
                'left_index', 'right_index', 'left_thumb', 'right_thumb',
                'left_hip', 'right_hip', 'left_knee', 'right_knee',
                'left_ankle', 'right_ankle', 'left_heel', 'right_heel',
                'left_foot_index', 'right_foot_index'
            ]
            
            for landmark in landmark_names:
                for coord in ['x', 'y', 'z', 'visibility']:
                    feature_names.append(f"{landmark}_{coord}")
            
            importance_dict = dict(zip(feature_names, self.rf_model.feature_importances_))
            return dict(sorted(importance_dict.items(), key=lambda x: x[1], reverse=True))
        
        return {}

# Example usage and training script
async def main():
    """Main function to train the video exercise classifier"""
    print("="*70)
    print("üèãÔ∏è  VIDEO EXERCISE CLASSIFIER - ENSEMBLE MODEL TRAINING")
    print("="*70)
    print("\nüì¶ Ensemble Configuration:")
    print("   1Ô∏è‚É£  Random Forest (300 estimators)")
    print("   2Ô∏è‚É£  Gradient Boosting (200 estimators)")
    print("   3Ô∏è‚É£  Support Vector Machine (RBF kernel)")
    print("   üó≥Ô∏è  Voting Strategy: Soft (probability-based)")
    print("="*70)
    
    classifier = VideoExerciseClassifier()
    
    # Train the model
    try:
        accuracy = await classifier.train_model()
        print(f"\nüéâ Training completed with {accuracy:.2%} accuracy!")
        print("\n‚ú® Ensemble Benefits:")
        print("   ‚Ä¢ Combines strengths of 3 different algorithms")
        print("   ‚Ä¢ Reduces overfitting through model diversity")
        print("   ‚Ä¢ Improved generalization on unseen data")
        print("   ‚Ä¢ More robust predictions")
        
        # Show feature importance from Random Forest
        print("\nüîç Top 10 Most Important Features (from Random Forest):")
        importance = classifier.get_feature_importance()
        for i, (feature, score) in enumerate(list(importance.items())[:10]):
            print(f"{i+1:2d}. {feature}: {score:.4f}")
            
    except Exception as e:
        print(f"‚ùå Training failed: {e}")

if __name__ == "__main__":
    asyncio.run(main())
